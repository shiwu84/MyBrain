（1）国内研究动态

之前，研究者们知道大语言模型（LLMs）更新慢，而且会胡编乱造（幻觉）。专业领域需要高准确性。所以，研究重点是用 RAG 引入外部知识来解决 LLMs 的知识缺陷。

现在核心目标是集中在保障数据安全和本地化部署。许多中小企业预算少，硬件旧。它们现在用小参数中文模型（像 ChatGLM）安全、低成本地回答专业问题。

他们用两种主要方法：

1. 混合检索：这结合了向量检索（理解长文本语义）和知识图谱（确保逻辑和可追溯性）。知识图谱保证了推理的逻辑性。
    
2. 多智能体协同：复杂的任务会被分解。多个本地小模型（智能体）顺序合作完成问答。
    
王祎（2025年5月）的研究把 RAG 和知识图谱用在红色档案管理上。系统可以本地部署，保证安全。另一个例子，王志远、张伟、官炳政、杨慧丽（2025年9月19日）提出了 MSCG-RAG 方法。MSCG-RAG 用多智能体协同来解决工业问答中低成本部署的难题。

红色档案这类公开数据量少，知识库构建不完整。尽管有优化，小模型的推理能力仍是瓶颈，尤其在处理复杂多跳推理时表现不好。

（2）国外研究动态

国外研究一开始偏向基础理论和架构迭代。早期是“朴素 RAG”，只有简单的检索和生成。他们主要关注基础的检索质量。

 
目标是让 RAG 系统变得自主和有智慧。现在的趋势是 Agentic RAG 框架。研究重点是建立严格的闭环优化机制来自己检查错误。

关键技术包括：

1. 自我批判：模型生成答案时会评估检索内容的质量和相关性。它可以自适应地调整检索和生成。
    
2. 闭环验证和规划：复杂的系统分解问题，并用双重验证（事实验证和逻辑验证）检查答案。如果发现错误，系统记录缺陷规则并重新规划，实现自我修正。
    
3. 持续学习：张伟（2025年5月）提出了 MKG 框架。它引入了元知识（Meta-Knowledge）记忆机制。元知识包括成功和失败的经验。这让模型可以持续学习并优化推理过程。
    

Asai A., Wu Z., Wang Y., 等（2024）提出了 Self-RAG，它教会大模型通过“反射标记”进行“自我批判”。张浩然、郝文宁、靳大尉、程恺、刘君阳（2025年10月17日）提出了 PR-RAG 框架。PR-RAG 使用任务规划和反思模块实现自我修正。另外，Yiqun Chen、Erhan Zhang、Lingyong Yan、Shuaiqiang Wang、Jizhou Huang、Dawei Yin 和 Jiaxin Mao（2025年8月）提出的 MMOA-RAG 框架使用多智能体强化学习对 RAG 的多个模块进行联合优化。

 
智能体间的协同决策机制还需要优化。LLM 的幻觉仍可能影响系统的自我评估和验证结果的准确性。系统还需要提升在大规模知识库中快速检索的效率。



（1）国内研究动态

之前怎么研究的  
早期研究者发现大语言模型（LLMs）更新慢、容易出现幻觉，难以满足专业领域对高准确性的需求。因此，研究重点集中在通过 RAG 引入外部知识，以弥补模型的知识缺陷。

现在集中在哪些方面  
当前国内研究主要关注数据安全与本地化部署。由于中小企业预算有限、硬件条件受限，研究者普遍采用小参数中文模型（如 ChatGLM）来实现安全、低成本的问答系统。研究方向主要包括混合检索与多智能体协同。前者结合语义检索与知识图谱以提升准确性，后者通过多个小模型协作完成复杂任务。近年来，王祎（2025）将 RAG 与知识图谱用于红色档案管理，实现了安全可控的本地部署；王志远等（2025）提出的 MSCG-RAG 方法则通过多智能体协同优化工业问答的部署效率。

目前的研究还有什么不足  
红色档案等领域的数据资源有限，知识库构建不完整。同时，小模型的推理能力仍显不足，在处理复杂任务时存在性能瓶颈。

（2）国外研究动态

之前怎么研究的  
国外早期研究以理论与架构探索为主，RAG 系统多采用简单的检索与生成方式，重点关注检索质量与生成相关性。

现在集中在哪些方面  
目前，国外研究重心转向构建更智能、自主的 RAG 系统。代表性的方向包括 Agentic RAG 框架与自我优化机制，强调系统在检索、生成和验证环节的自我检查与修正。例如，Self-RAG 模型引入“反思”机制，PR-RAG 框架融合任务规划与反思模块，MMOA-RAG 则利用多智能体强化学习实现系统优化。这些研究都体现出 RAG 正在向智能化和持续学习方向发展。

目前的研究还有什么不足  
尽管国外研究在自我优化方面取得进展，但智能体间的协同仍需改进。模型幻觉问题依然存在，影响系统的自我评估与验证准确性。同时，大规模知识检索的效率仍有待提升。